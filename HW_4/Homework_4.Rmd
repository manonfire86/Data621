---
title: "Homework 4"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(DataExplorer)
library(knitr)
library(psych)
library(caret)
library(gridExtra)
library(geoR)
```

# HOMEWORK 4

Hector Santana, Zachary Safir, Mario Pena
 
In this assignment we will explore, analyze and build a multiple linear regression and binary logistic model based on auto insurance data to predict the probability that a person will crash their car and the amount of money it would cost in the event of that person crashing the car.

We are provided with information on a little over 8,000 customers at an auto insurance company. Each record has two response variables. TARGET_FLAG has a response of 1 if the customer was involved in a crash, or 0 if the customer was not involved in a crash.TARGET_AMT has a response of 0 if the customer did not crash their car, or a value greater than 0 otherwise. Additionally, there are 23 predictor variables in the data that could be of use for the model.

We first download the "training" and "evaluation" datasets from GitHub:

```{r Data Importation}
training <- read.csv("https://raw.githubusercontent.com/manonfire86/Data621/main/HW_4/insurance_training_data.csv", header=TRUE, sep=",")

evaluation <- read.csv("https://raw.githubusercontent.com/manonfire86/Data621/main/HW_4/insurance-evaluation-data.csv", header=TRUE, sep=",")

training$TARGET_FLAG <- as.factor(training$TARGET_FLAG)
```

Before we begin the data exploration process we will clean our data a bit in order to run summary statistics and plots accurately and effectively.

We created a function to eliminate "$" and "," characters from the data, which will cause R to misread the data points and calculate inaccurate results.

```{r CleanData}
clean_char <- function(vector) {
    i <- unname(sapply(vector, str_replace_all, '[,$]', ''))
    i <- as.numeric(i)
    return(i)
}  
training$INCOME <- clean_char(training$INCOME)
training$HOME_VAL <- clean_char(training$HOME_VAL)
training$BLUEBOOK <- clean_char(training$BLUEBOOK)
training$OLDCLAIM <- clean_char(training$OLDCLAIM)

evaluation$INCOME <- clean_char(evaluation$INCOME)
evaluation$HOME_VAL <- clean_char(evaluation$HOME_VAL)
evaluation$BLUEBOOK <- clean_char(evaluation$BLUEBOOK)
evaluation$OLDCLAIM <- clean_char(evaluation$OLDCLAIM)
```  


# DATA EXPLORATION

Below we have created a table with the summary statistics of our 23 predictor variables.

```{r, echo=FALSE, warning=FALSE}
summary <- describe(training[,c(4:26)])[,c(2:5,8,9,11,12)]
knitr::kable(summary)
```  

According to our summary statistics above, and our graph below, there are a few columns (variables) that have missing values. These include "AGE", "INCOME", "YOJ", "HOME_VAL", and "CAR_AGE".

```{r}
plot_missing(training)
```

We can also observe that the "TARGET_FAG" variable is not evenly distributed between the "0" and "1" responses. We have more than double the amount of 0 responses throughout the data.

```{r}
prop.table(table(training$TARGET_FLAG))
```

The insight gained from the statistical analysis permitted us to make note of further data of interest that needed to be analyzed in depth prior to the creation of our models. To confirm these irregularities we then constructed visual representations consisting of density plots, histograms, and boxplots.

```{r}
quant_var <- split_columns(training)
plot_histogram(quant_var$continuous)
```

```{r}
plot_bar(quant_var$discrete)
```

```{r}
plot_density(quant_var$continuous)
```

```{r}
plot_boxplot(
  data = training,
  by = "TARGET_FLAG")+ 
  geom_jitter()
```

